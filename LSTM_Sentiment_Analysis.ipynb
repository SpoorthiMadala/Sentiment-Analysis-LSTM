{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# LSTM for Sentiment Analysis\n", "\n", "This notebook demonstrates the implementation of an **LSTM model** for sentiment classification using a movie reviews dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from collections import Counter\n", "from sklearn.preprocessing import LabelEncoder\n", "from keras.preprocessing import sequence\n", "from keras.models import Sequential\n", "from keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n", "import re\n", "import nltk\n", "from nltk.corpus import stopwords\n", "from nltk.tokenize import word_tokenize\n", "nltk.download('punkt')\n", "nltk.download('stopwords')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def clean_text(text):\n", "    text = re.sub(r\"<.*?>\", \"\", text)\n", "    text = re.sub(r\"[^a-zA-Z']\", \" \", text)\n", "    tokens = text.lower().split()\n", "    return \" \".join([t for t in tokens if t not in stopwords.words('english')])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df = pd.read_csv(\"movie_reviews.csv\")\n", "df['clean_review'] = df['review'].apply(clean_text)\n", "\n", "train_size = 800\n", "train_reviews = df['clean_review'][:train_size]\n", "test_reviews = df['clean_review'][train_size:]\n", "train_labels = df['sentiment'][:train_size]\n", "test_labels = df['sentiment'][train_size:]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tokenized_train = [text.split() for text in train_reviews]\n", "tokenized_test = [text.split() for text in test_reviews]\n", "token_counter = Counter(token for review in tokenized_train for token in review)\n", "vocab_map = {word: idx + 1 for idx, (word, _) in enumerate(token_counter.items())}\n", "vocab_map['PAD_INDEX'] = 0\n", "vocab_map['NOT_FOUND_INDEX'] = len(vocab_map)\n", "vocab_size = len(vocab_map)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def encode_and_pad(texts, vocab, max_len):\n", "    encoded = [[vocab.get(token, vocab['NOT_FOUND_INDEX']) for token in review.split()] for review in texts]\n", "    return sequence.pad_sequences(encoded, maxlen=max_len)\n", "\n", "max_len = max(len(review.split()) for review in train_reviews)\n", "X_train = encode_and_pad(train_reviews, vocab_map, max_len)\n", "X_test = encode_and_pad(test_reviews, vocab_map, max_len)\n", "\n", "le = LabelEncoder()\n", "y_train = le.fit_transform(train_labels)\n", "y_test = le.transform(test_labels)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["embedding_dim = 128\n", "lstm_units = 64\n", "\n", "model = Sequential([\n", "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_len),\n", "    SpatialDropout1D(0.2),\n", "    LSTM(lstm_units, dropout=0.2, recurrent_dropout=0.2),\n", "    Dense(1, activation='sigmoid')\n", "])\n", "\n", "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n", "model.summary()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model.fit(X_train, y_train, batch_size=100, epochs=5, validation_split=0.1, verbose=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n", "y_pred_prob = model.predict(X_test)\n", "y_pred = (y_pred_prob > 0.5).astype(int)\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"Precision:\", precision_score(y_test, y_pred))\n", "print(\"Recall:\", recall_score(y_test, y_pred))\n", "print(\"F1 Score:\", f1_score(y_test, y_pred))\n", "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=le.classes_))\n", "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Confusion Matrix Output\n", "![Results](sentiment-analysis.png)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}
